{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1-Tokenization\n",
        "\n",
        "**Definition:**  \n",
        "The process of breaking text into smaller units such as words, subwords, or characters.\n",
        "\n",
        "## **Types:**\n",
        "\n",
        "### **1. Word Tokenization**  \n",
        "Splitting text into individual words.\n",
        "\n",
        "**Example:**  \n",
        "Input:  \n",
        "`\"I study Machine Learning on GeeksforGeeks.\"`  \n",
        "Output:  \n",
        "`['I', 'study', 'Machine', 'Learning', 'on', 'GeeksforGeeks', '.']`  \n",
        "\n",
        "---\n",
        "\n",
        "### **2. Sentence Tokenization**  \n",
        "Splitting text into individual sentences.\n",
        "\n",
        "**Example:**  \n",
        "Input:  \n",
        "`\"I study Machine Learning on GeeksforGeeks. Currently, I'm studying NLP.\"`  \n",
        "Output:  \n",
        "`['I study Machine Learning on GeeksforGeeks.', 'Currently, I'm studying NLP.']`  \n",
        "\n",
        "---\n",
        "\n",
        "### **3. Subword Tokenization**  \n",
        "Breaking words into smaller units like prefixes, suffixes, or individual characters.\n",
        "\n",
        "---\n",
        "\n",
        "### **Importance:**  \n",
        "Tokenization is the first step in many NLP pipelines and directly impacts subsequent processing stages.\n"
      ],
      "metadata": {
        "id": "o10HjQ-kWVBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2-Stemming**\n",
        "\n",
        "## **Definition:**  \n",
        "The process of reducing words to their root form by stripping suffixes and prefixes.\n",
        "\n",
        "## **Example:**  \n",
        "- \"running\" → \"run\"  \n",
        "- \"runner\" → \"run\"  \n",
        "\n",
        "## **Difference from Lemmatization:**  \n",
        "- Stemming is a more crude technique that may not always produce real words.  \n",
        "- Example: \"better\" → \"bet\" (stemming) vs. \"better\" → \"good\" (lemmatization).  \n"
      ],
      "metadata": {
        "id": "I7isFVyEW85z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# create an object of class PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "print(stemmer.stem(\"Communication\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHgcDfKpXEcc",
        "outputId": "66c95598-515f-4ea8-8b66-d0d26e04f2ce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "commun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3-Lemmatization**\n",
        "\n",
        "## **Definition:**  \n",
        "The process of reducing a word to its base or dictionary form, called a lemma.\n",
        "\n",
        "## **Example:**  \n",
        "- \"running\" → \"run\"  \n",
        "- \"ran\" → \"run\"  \n",
        "\n",
        "## **Importance:**  \n",
        "Lemmatization helps in understanding the underlying meaning of words by grouping different forms of a word.\n",
        "\n",
        "## **Comparison with Stemming:**  \n",
        "- Stemmers are faster and computationally less expensive than lemmatizers.  \n",
        "- Lemmatization provides more accurate and meaningful results compared to stemming.\n"
      ],
      "metadata": {
        "id": "GnjRde4CXV-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REewF2wDfZGa",
        "outputId": "746522e4-180d-4dcd-c3ef-359a60ae91ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# create an object of class WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(lemmatizer.lemmatize(\"Communication\", 'v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJZnY_APfE4z",
        "outputId": "af4e3133-32df-4d86-8cee-abe77c7cdafd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Communication\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-Normalization\n",
        "\n",
        "Normalization, Doğal Dil İşleme (NLP) sürecinde metnin standart bir forma dönüştürülmesi işlemidir. Bu işlem, metin verilerinin tutarlı bir şekilde işlenmesini sağlamak amacıyla yapılır. Normalization, NLP modellerinin metni daha iyi anlamasını ve yorumlamasını kolaylaştırır. Yaygın normalization teknikleri arasında metni küçük harflere dönüştürme (lowercasing), noktalama işaretlerini kaldırma, stop words (gereksiz kelimeler) çıkarma gibi işlemler yer alır.\n",
        "\n",
        "#### 1. Lowercasing\n",
        "Lowercasing, metindeki tüm karakterleri küçük harfe dönüştürmeyi içerir. Bu işlem, \"Apple\" ve \"apple\" gibi kelimelerin aynı kelime olarak kabul edilmesini sağlar.\n",
        "\n",
        "**Örnek:**\n",
        "- \"Apple\" -> \"apple\"\n",
        "\n",
        "#### 2. Removing Punctuation\n",
        "Noktalama işaretleri, genellikle metnin anlamını değiştirmediği için çoğu NLP görevinde çıkarılır. Bu işlem, gereksiz semboller ve işaretlerin metni bozmasını engeller.\n",
        "\n",
        "**Örnek:**\n",
        "- \"Hello, world!\" -> \"Hello world\"\n",
        "\n",
        "#### 3. Removing Stopwords\n",
        "Stop words, metinlerde sıkça bulunan ve genellikle anlam taşımayan kelimelerdir. Örneğin, \"the\", \"is\", \"and\" gibi kelimeler çoğu dil işleme görevinde gereksiz kabul edilir ve çıkarılabilir.\n",
        "\n",
        "**Örnek:**\n",
        "- \"This is a pen\" -> \"pen\""
      ],
      "metadata": {
        "id": "2CylBiPviRgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "# Download the 'punkt_tab' resource\n",
        "nltk.download('punkt_tab') # Downloading the Punkt sentence tokenizer model.\n",
        "\n",
        "# nltk veri kümesini indiriyoruz\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Sample text\n",
        "text = \"Running is better than walking! Apples and oranges are different.\"\n",
        "\n",
        "# 1. Lowercasing (Küçük harfe dönüştürme)\n",
        "text_lower = text.lower()\n",
        "print(\"Lowercased text:\", text_lower)\n",
        "\n",
        "# 2. Removing punctuation (Noktalama işaretlerini kaldırma)\n",
        "text_no_punct = re.sub(r'[^\\w\\s]', '', text_lower)\n",
        "print(\"Text without punctuation:\", text_no_punct)\n",
        "\n",
        "# 3. Tokenization (Kelime token'larına ayırma)\n",
        "words = nltk.word_tokenize(text_no_punct)\n",
        "print(\"Tokenized words:\", words)\n",
        "\n",
        "# 4. Removing stop words (Stop word'leri kaldırma)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "words_no_stop = [word for word in words if word not in stop_words]\n",
        "print(\"Text without stopwords:\", words_no_stop)\n",
        "\n",
        "# 5. Stemming (Kelimeleri köklerine indirme)\n",
        "ps = PorterStemmer()\n",
        "words_stemmed = [ps.stem(word) for word in words_no_stop]\n",
        "print(\"Stemmed words:\", words_stemmed)\n",
        "\n",
        "# 6. Lemmatization (Kelimeleri lemmatize etme)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words_lemmatized = [lemmatizer.lemmatize(word) for word in words_no_stop]\n",
        "print(\"Lemmatized words:\", words_lemmatized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtoBin_8j-R9",
        "outputId": "ccb91527-f5d2-4c9b-9ae7-9449059af4de"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercased text: running is better than walking! apples and oranges are different.\n",
            "Text without punctuation: running is better than walking apples and oranges are different\n",
            "Tokenized words: ['running', 'is', 'better', 'than', 'walking', 'apples', 'and', 'oranges', 'are', 'different']\n",
            "Text without stopwords: ['running', 'better', 'walking', 'apples', 'oranges', 'different']\n",
            "Stemmed words: ['run', 'better', 'walk', 'appl', 'orang', 'differ']\n",
            "Lemmatized words: ['running', 'better', 'walking', 'apple', 'orange', 'different']\n"
          ]
        }
      ]
    }
  ]
}